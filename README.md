# Generalized Linear Mixed‚Äêeffects Model in Python

or the many ways to perform GLMM in python playground
  
A comparison among:  
[StatsModels](https://github.com/statsmodels/statsmodels)  
[Theano](https://github.com/Theano/Theano)  
[PyMC3](https://github.com/pymc-devs/pymc3)(Base on Theano)  
[TensorFlow](https://github.com/tensorflow/tensorflow)  
[Stan](https://github.com/stan-dev/stan) and [pyStan](https://github.com/stan-dev/pystan)  
[Keras](https://github.com/fchollet/keras)  
[edward](https://github.com/blei-lab/edward)  

Whenever I try on some new machine learning or statistical package, I will fit a mixed effect model. It is better than linear regression (or MNIST for that matter, as it is just a large logistic regression) since linear regressions are almost too easy to fit. Hence this collection of codes that all doing (more or less) the same thing.

## TODO
Estimate uncertainty related to model parameter using [dropout](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html) in Theano and TensorFlow  
[DROPOUT AS A BAYESIAN APPROXIMATION](http://mlg.eng.cam.ac.uk/yarin/publications.html#Gal2015Bayesian)  
K-Fold Cross Validation and Leave-One-Out (LOO)  
[WAIC and cross-validation in Stan](http://www.stat.columbia.edu/~gelman/research/unpublished/waic_stan.pdf)  
[tyarkoni/PPS2016](https://github.com/tyarkoni/PPS2016)

## More information (codes) could be found below (to name a few):  
[paul-buerkner/brms](https://github.com/paul-buerkner/brms)  
[vasishth/BayesLMMTutorial](https://github.com/vasishth/BayesLMMTutorial)  
[jonsedar/pymc3_vs_pystan](https://github.com/jonsedar/pymc3_vs_pystan)  
[Example from PyMC3](http://pymc-devs.github.io/pymc3/notebooks/GLM-hierarchical.html)  
[tyarkoni/nipymc](https://github.com/tyarkoni/nipymc)  
[bambinos/bambi](https://github.com/bambinos/bambi)  
